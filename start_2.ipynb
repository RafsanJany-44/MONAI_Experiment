{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d59a0e93-2ff9-4965-a676-bd18f68c59e3",
   "metadata": {},
   "source": [
    "#40 Slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4a03daed-0783-4328-a2ca-ef34f99b804a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#in_path = \"C:/Users/RAZER/Downloads/Task09_Spleen/dicm_files/labels\"\n",
    "\n",
    "#out_path = \"C:/Users/RAZER/Downloads/Task09_Spleen/dicm_groups/labels\"\n",
    "\n",
    "in_path = \"C:/Users/RAZER/Downloads/Task09_Spleen/dicm_files/images\"\n",
    "out_path = \"C:/Users/RAZER/Downloads/Task09_Spleen/dicm_groups/images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6257ce04-2c27-488a-b655-eb892a860068",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install glob2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7179c4b1-5d09-4b58-a794-6195ba762355",
   "metadata": {},
   "source": [
    "to moving the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a8834b-ca25-4742-9a5e-d2acec112f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytest-shutil                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0036782-929d-4672-a1a8-99c433510492",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c44fb605-a90a-418f-9fb2-615337c648fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def move_file(path_in,path_out,move = False,count = 0):\n",
    "    if count <=0:                                                            #calculating least file count\n",
    "        size_count = []\n",
    "        for i in glob(path+\"/*\"):\n",
    "            size_count.append(len(glob(i+\"/*\")))\n",
    "        count = min(size_count)\n",
    "    \n",
    "\n",
    "    for i in glob(path_in + \"/*\"):\n",
    "        i_name = os.path.basename(os.path.normpath(i))                       \n",
    "        num_of_folders = int(len(glob(i+\"/*\"))/count)                       #calculating number of folders\n",
    "        print('Total Files In Input_File('+i+\"): \"+str(len(glob(i+\"/*\"))))\n",
    "\n",
    "        for j in range(1,num_of_folders+1):                                 #making new directories\n",
    "            out_new_dir = os.path.join(path_out, i_name+\"_\"+str(j))\n",
    "            os.mkdir(out_new_dir)\n",
    "            \n",
    "            k=1\n",
    "            for file in glob(i+\"/*\"):\n",
    "                if k ==count+1:\n",
    "                    break\n",
    "                if move == False:\n",
    "                    shutil.copy(file, out_new_dir)\n",
    "                else:\n",
    "                    shutil.move(file,out_new_dir)\n",
    "                k+=1\n",
    "            print(\"Total Files In Output directory(\"+out_new_dir+\") :\",k-1)\n",
    "        print(\"----------------------------------------------------------------\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5d1b3df1-222b-410a-8464-8e3db50fefec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Files In Input_File(C:/Users/RAZER/Downloads/Task09_Spleen/lets_work/dicm_files/images\\img_2): 90\n",
      "Total Files In Output directory(C:/Users/RAZER/Downloads/Task09_Spleen/lets_work/dicm_groups/images\\img_2_1) : 40\n",
      "Total Files In Output directory(C:/Users/RAZER/Downloads/Task09_Spleen/lets_work/dicm_groups/images\\img_2_2) : 40\n",
      "----------------------------------------------------------------\n",
      "Total Files In Input_File(C:/Users/RAZER/Downloads/Task09_Spleen/lets_work/dicm_files/images\\img_3): 40\n",
      "Total Files In Output directory(C:/Users/RAZER/Downloads/Task09_Spleen/lets_work/dicm_groups/images\\img_3_1) : 40\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "path = \"C:/Users/RAZER/Downloads/Task09_Spleen/lets_work/dicm_files/images\"\n",
    "path2 = \"C:/Users/RAZER/Downloads/Task09_Spleen/lets_work/dicm_groups/images\"\n",
    "\n",
    "move_file(path,path2,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48bbcd0-825d-4d31-a178-018a3bccd1bc",
   "metadata": {},
   "source": [
    "#Convert dicom to nifties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fe6655-de47-4c57-98e9-64e08504092d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dicom2nifti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e02b098a-1b21-4744-86fd-907519103d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dicom2nifti\n",
    "\n",
    "\n",
    "def dicom_to_nifty(path_in, path_out):\n",
    "\n",
    "    file_list = glob(path_in)\n",
    "    for i in file_list:\n",
    "        i_name = os.path.basename(os.path.normpath(i))\n",
    "        dicom2nifti.dicom_series_to_nifti(i,os.path.join(path_out, i_name + \".nii.gz\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c062cc03-5503-4279-974c-369b645b9b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path_images = \"C:/Users/RAZER/Downloads/Task09_Spleen/lets_work/dicm_groups/images/*\"\n",
    "\n",
    "in_path_labels = \"C:/Users/RAZER/Downloads/Task09_Spleen/lets_work/dicm_groups/labels/*\"\n",
    "\n",
    "\n",
    "out_path_images = \"C:/Users/RAZER/Downloads/Task09_Spleen/lets_work/niftis_files/images\"\n",
    "\n",
    "out_path_labels = \"C:/Users/RAZER/Downloads/Task09_Spleen/lets_work/niftis_files/labels\"\n",
    "\n",
    "\n",
    "dicom_to_nifty(in_path_labels,out_path_labels)\n",
    "dicom_to_nifty(in_path_images,out_path_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41324648-156d-4915-8501-79a2e7fec1db",
   "metadata": {},
   "source": [
    "#Find Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21751b92-4308-4a69-83ef-72f80e9ce353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133a9c9b-6013-462f-9665-2f18c72eada3",
   "metadata": {},
   "source": [
    "we will see the value of pixels. more then only one value means -> contains labels, 0 for the background and 1 for the forground. only zero means -> only background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d2acea3-265e-4df6-9e3f-c6c6584609eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_of = \"C:/Users/RAZER/Downloads/Task09_Spleen/lets_work/niftis_files/labels/*\"\n",
    "\n",
    "\n",
    "\n",
    "def find_only_bg(path):\n",
    "    \n",
    "    list_of = []\n",
    "    \n",
    "    for i in glob(path):\n",
    "        nifti_file = nib.load(i)\n",
    "\n",
    "        frame_data =  nifti_file.get_fdata()                            #this giving the infos abour frame\n",
    "\n",
    "        np_unique = np.unique(frame_data)                               #this will give the unique values of the frame\n",
    "\n",
    "        if len(np_unique) == 1:\n",
    "            list_of.append(os.path.basename(os.path.normpath(i)))\n",
    "            \n",
    "    return list_of\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ce3d806-70e1-455a-9906-0bede9a291f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_usable = find_only_bg(path_of)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01553e9c-2aaf-4641-825c-3a78859cfb0e",
   "metadata": {},
   "source": [
    "#PreProcessing\n",
    "\n",
    "-> cuda <br>\n",
    "-> cudnn <br>\n",
    "-> monai <br>\n",
    "-> pytorch <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c0d5072-65fe-4198-a44d-c4b5f48c3345",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU \"monai[ignite, nibabel, torchvision, tqdm]==0.6.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "973eae90-efeb-4f1c-b1fc-23d98b3cd556",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from monai.transforms import(\n",
    "    Compose,\n",
    "    AddChanneld,\n",
    "    LoadImaged,\n",
    "    Resized,\n",
    "    ToTensord,\n",
    "    Spacingd,\n",
    "    Orientationd,\n",
    "    ScaleIntensityRanged,\n",
    "    CropForegroundd,\n",
    ")\n",
    "from monai.data import DataLoader, Dataset, CacheDataset\n",
    "from monai.utils import set_determinism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b55225-92e1-49c3-9756-3ed44b8e6a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(in_dir, pixdim=(1.5, 1.5, 1.0), a_min=-200, a_max=200, spatial_size=[128,128,64], cache=False):\n",
    "\n",
    "    \"\"\"\n",
    "    This function is for preprocessing, it contains only the basic transforms, but you can add more operations that you \n",
    "    find in the Monai documentation.\n",
    "    https://monai.io/docs.html\n",
    "    \"\"\"\n",
    "\n",
    "    set_determinism(seed=0)\n",
    "\n",
    "    path_train_volumes = sorted(glob(os.path.join(in_dir, \"TrainVolumes\", \"*.nii.gz\")))\n",
    "    path_train_segmentation = sorted(glob(os.path.join(in_dir, \"TrainSegmentation\", \"*.nii.gz\")))\n",
    "\n",
    "    path_test_volumes = sorted(glob(os.path.join(in_dir, \"TestVolumes\", \"*.nii.gz\")))\n",
    "    path_test_segmentation = sorted(glob(os.path.join(in_dir, \"TestSegmentation\", \"*.nii.gz\")))\n",
    "\n",
    "    train_files = [{\"vol\": image_name, \"seg\": label_name} for image_name, label_name in zip(path_train_volumes, path_train_segmentation)]\n",
    "    test_files = [{\"vol\": image_name, \"seg\": label_name} for image_name, label_name in zip(path_test_volumes, path_test_segmentation)]\n",
    "\n",
    "    train_transforms = Compose(\n",
    "        [\n",
    "            LoadImaged(keys=[\"vol\", \"seg\"]),\n",
    "            AddChanneld(keys=[\"vol\", \"seg\"]),\n",
    "            Spacingd(keys=[\"vol\", \"seg\"], pixdim=pixdim, mode=(\"bilinear\", \"nearest\")),\n",
    "            Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n",
    "            ScaleIntensityRanged(keys=[\"vol\"], a_min=a_min, a_max=a_max, b_min=0.0, b_max=1.0, clip=True), \n",
    "            CropForegroundd(keys=[\"vol\", \"seg\"], source_key=\"vol\"),\n",
    "            Resized(keys=[\"vol\", \"seg\"], spatial_size=spatial_size),   \n",
    "            ToTensord(keys=[\"vol\", \"seg\"]),\n",
    "\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    test_transforms = Compose(\n",
    "        [\n",
    "            LoadImaged(keys=[\"vol\", \"seg\"]),\n",
    "            AddChanneld(keys=[\"vol\", \"seg\"]),\n",
    "            Spacingd(keys=[\"vol\", \"seg\"], pixdim=pixdim, mode=(\"bilinear\", \"nearest\")),\n",
    "            Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n",
    "            ScaleIntensityRanged(keys=[\"vol\"], a_min=a_min, a_max=a_max,b_min=0.0, b_max=1.0, clip=True), \n",
    "            CropForegroundd(keys=['vol', 'seg'], source_key='vol'),\n",
    "            Resized(keys=[\"vol\", \"seg\"], spatial_size=spatial_size),   \n",
    "            ToTensord(keys=[\"vol\", \"seg\"]),\n",
    "\n",
    "            \n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if cache:\n",
    "        train_ds = CacheDataset(data=train_files, transform=train_transforms,cache_rate=1.0)\n",
    "        train_loader = DataLoader(train_ds, batch_size=1)\n",
    "\n",
    "        test_ds = CacheDataset(data=test_files, transform=test_transforms, cache_rate=1.0)\n",
    "        test_loader = DataLoader(test_ds, batch_size=1)\n",
    "\n",
    "        return train_loader, test_loader\n",
    "\n",
    "    else:\n",
    "        train_ds = Dataset(data=train_files, transform=train_transforms)\n",
    "        train_loader = DataLoader(train_ds, batch_size=1)\n",
    "\n",
    "        test_ds = Dataset(data=test_files, transform=test_transforms)\n",
    "        test_loader = DataLoader(test_ds, batch_size=1)\n",
    "\n",
    "        return train_loader, test_loader"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
